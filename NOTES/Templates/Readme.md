# Project Report - < Project NAME >


## Goals

```
> What is this project going to achieve?
-  

> How will the end users use this system?
-
```

## Performance Constraints
```
> How fast/good does the prediction have to be?
-

> How costly are false predictions going to be?
-
```

## Evaluation
```
> How were the performances of the system evaluated, during Training?
-

> How were the performances of the system evaluated, during Interferencing?
- 
```

## Personalization
```
> How personalized is the model? Is there a generalised model for everyone, or for each user?
-
```


## Project Constraints
```
> How much time was it taken until deployment.
-

> What computer power was available?
-
```

### Data Availability and Collection
```
> What is the source of data and how was it collected?
-

> Is it annotated and if so, how good is the annotation?
-

> What data is needed from users, and if so, how was the data collected?
-

> How is User Data Privacy challenges handled?
```

### Storage & Size
```
> Where is the data currently stored: on the cloud, local, or on the users'
devices?
-

> What is the size of data?
-

-
```

### Data preprocessing & representation

#### Feature Engineering
#### Normalization
#### Imputation
#### Correlation Presence

### Modeling

#### Baseline
```
> Baseline Predictions
- 

> Baseline Models used
- 
```

#### Deployed Models & Evaluation
```
> How did you decide what models to use? What models did eventually try? What
models did better? Why? Any surprise?
```

### Evaluation
```
> How did you evaluate your models?
-
```

### Lessons 
```
> If the project were to be done again, what should be done differently?
-
```

